{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM,Dense, Conv1D, MaxPooling1D, Bidirectional, Dropout, Input, Embedding\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.utils import shuffle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = []\n",
    "labels = []\n",
    "\n",
    "with open(\"data/restaurants.json\", \"r\") as jfile:\n",
    "    data = json.load(jfile)\n",
    "    \n",
    "    for dialogue in data:\n",
    "        turns = dialogue[\"turns\"]\n",
    "        for turn in turns:\n",
    "            speaker = turn[\"speaker\"]\n",
    "            if speaker == \"USER\":\n",
    "                utterance, intent = turn[\"utterance\"], turn[\"intent\"]\n",
    "                label = 1 if intent == \"FindRestaurants\" else 0\n",
    "                utterances.append(utterance)\n",
    "                labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am feeling hungry so I would like to find a place to eat.',\n",
       " 'I would like for it to be in San Jose.',\n",
       " 'I usually like eating the American type of food.',\n",
       " 'Can you give me the address of this restaurant.',\n",
       " 'Can you give me the phone number that I can contact them with?',\n",
       " 'Is there some other restaurant which you can suggest?',\n",
       " 'Do you have another restaurant matching my needs? For example a restaurant which is economical and is located in Palo Alto.',\n",
       " 'Alright, that seems good. I would like to make a booking at this restaurant.',\n",
       " 'I will be eating there at 11:30 am so make it for then.',\n",
       " 'That suits me well. Can you tell me if they feature live music?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1233, 1233)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utterances), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances, labels = shuffle(utterances, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(char_level=True,filters=\".,;'\\\"-\", lower=True)\n",
    "tokenizer.fit_on_texts(utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1,\n",
       " 'e': 2,\n",
       " 'a': 3,\n",
       " 't': 4,\n",
       " 'o': 5,\n",
       " 'n': 6,\n",
       " 'i': 7,\n",
       " 'r': 8,\n",
       " 's': 9,\n",
       " 'h': 10,\n",
       " 'l': 11,\n",
       " 'd': 12,\n",
       " 'u': 13,\n",
       " '.': 14,\n",
       " 'm': 15,\n",
       " 'c': 16,\n",
       " 'y': 17,\n",
       " 'f': 18,\n",
       " 'p': 19,\n",
       " 'k': 20,\n",
       " 'g': 21,\n",
       " 'w': 22,\n",
       " 'v': 23,\n",
       " '?': 24,\n",
       " ',': 25,\n",
       " 'b': 26,\n",
       " \"'\": 27,\n",
       " '1': 28,\n",
       " ':': 29,\n",
       " '0': 30,\n",
       " '3': 31,\n",
       " '5': 32,\n",
       " 'x': 33,\n",
       " '4': 34,\n",
       " 'q': 35,\n",
       " '2': 36,\n",
       " '!': 37,\n",
       " 'z': 38,\n",
       " '7': 39,\n",
       " '6': 40,\n",
       " 'j': 41,\n",
       " '-': 42,\n",
       " '8': 43,\n",
       " '9': 44,\n",
       " '\"': 45,\n",
       " '`': 46}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = tokenizer.texts_to_sequences(utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    }
   ],
   "source": [
    "mutt_len = max([len(ans) for ans in utterances])\n",
    "\n",
    "print(mutt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17,\n",
       " 2,\n",
       " 9,\n",
       " 25,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 22,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 10,\n",
       " 2,\n",
       " 1,\n",
       " 28,\n",
       " 28,\n",
       " 4,\n",
       " 10]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = pad_sequences(utterances, MAX_LEN, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17,  2,  9, 25,  1,  7,  1, 22,  3,  6,  4,  1,  7,  4,  1,  5,  6,\n",
       "        1,  4, 10,  2,  1, 28, 28,  4, 10,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances, labels = np.array(utterances), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1233, 150), (1233,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_in = Input(shape=(MAX_LEN,))\n",
    "\n",
    "embedding_layer =  Embedding(input_dim = len(tokenizer.word_index)+1, output_dim = 100, input_length=MAX_LEN)\n",
    "lstm =  Bidirectional(LSTM(units=100, return_sequences=False))\n",
    "\n",
    "utt_embedding = embedding_layer(utt_in)\n",
    "utt_encoded = lstm(utt_embedding)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(utt_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(utt_in, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 150, 100)          4700      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 200)               160800    \n",
      "_________________________________________________________________\n",
      "classification_layer (Dense) (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 165,701\n",
      "Trainable params: 165,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 4s 228ms/step - loss: 0.6782 - accuracy: 0.5654 - val_loss: 0.6419 - val_accuracy: 0.7016\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 3s 193ms/step - loss: 0.5948 - accuracy: 0.7160 - val_loss: 0.5413 - val_accuracy: 0.6935\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 3s 193ms/step - loss: 0.5163 - accuracy: 0.7520 - val_loss: 0.5143 - val_accuracy: 0.7661\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 4s 201ms/step - loss: 0.4497 - accuracy: 0.7962 - val_loss: 0.4036 - val_accuracy: 0.8226\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 3s 194ms/step - loss: 0.3802 - accuracy: 0.8512 - val_loss: 0.3389 - val_accuracy: 0.8710\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 3s 194ms/step - loss: 0.3342 - accuracy: 0.8747 - val_loss: 0.3117 - val_accuracy: 0.8871\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 4s 202ms/step - loss: 0.3090 - accuracy: 0.8765 - val_loss: 0.3222 - val_accuracy: 0.8790\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 3s 194ms/step - loss: 0.3511 - accuracy: 0.8638 - val_loss: 0.4440 - val_accuracy: 0.8145\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 4s 195ms/step - loss: 0.4497 - accuracy: 0.8088 - val_loss: 0.4392 - val_accuracy: 0.8226\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 4s 210ms/step - loss: 0.3869 - accuracy: 0.8431 - val_loss: 0.4058 - val_accuracy: 0.8226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f69d8431f60>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(utterances, labels, validation_split=0.1, epochs = 10, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
